# An√°lise Multimodal de M√≠dia com IA

Este reposit√≥rio cont√©m dois projetos de Intelig√™ncia Artificial para an√°lise de conte√∫do multim√≠dia:

1.  **Analisador de √Åudio**: Um script que utiliza o modelo **Whisper da OpenAI** para transcrever √°udio para texto e, em seguida, aplica t√©cnicas de Processamento de Linguagem Natural (PLN) para analisar a frequ√™ncia das palavras.
2.  **Classificador de V√≠deo**: Um pipeline completo de Vis√£o Computacional que extrai frames de um v√≠deo, os processa, e treina uma **Rede Neural Convolucional (CNN)** com TensorFlow/Keras para classificar objetos contidos nos frames (livro, faca, celular).

## üé¨ V√≠deo Original

Este √© o v√≠deo utilizado como fonte de dados para o projeto de Vis√£o Computacional.

[![Assista ao V√≠deo]](https://youtube.com/shorts/at-nwAkwYv0)

## üöÄ Funcionalidades Principais

### An√°lise de √Åudio
-   Transcri√ß√£o de √°udio em portugu√™s para texto.
-   Limpeza e pr√©-processamento de texto (tokeniza√ß√£o, remo√ß√£o de stopwords, lematiza√ß√£o).
-   Contagem e visualiza√ß√£o das palavras mais frequentes em um gr√°fico de barras.

### An√°lise de V√≠deo
-   Separa√ß√£o autom√°tica de √°udio e v√≠deo de um arquivo `.mp4`.
-   Extra√ß√£o de frames de v√≠deo em intervalos regulares.
-   Armazenamento de frames como imagens (`.jpg`) e em formato FITS (`.fits`), com metadados.
-   Gest√£o de metadados dos frames em um banco de dados **SQLite**.
-   Pr√©-processamento de imagem, incluindo equaliza√ß√£o de histograma e segmenta√ß√£o de cores com K-Means.
-   T√©cnicas de balanceamento de dados (`RandomUnderSampler`).
-   *Data Augmentation* para enriquecer o dataset de treino (rota√ß√µes, zoom, brilho, etc.).
-   Treinamento e avalia√ß√£o de uma CNN para classifica√ß√£o de imagens multiclasse.
-   Visualiza√ß√£o detalhada dos resultados do modelo:
    -   M√©tricas de acur√°cia e perda.
    -   Relat√≥rio de classifica√ß√£o (precis√£o, recall, F1-score).
    -   Matriz de Confus√£o.
    -   Curva ROC.
    -   Visualiza√ß√£o dos filtros aprendidos pela CNN.

## üìÅ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ Analisando_√°udio.ipynb      # Notebook para transcri√ß√£o e an√°lise de √°udio.
‚îú‚îÄ‚îÄ Analisando_V√≠deo.ipynb      # Notebook para extra√ß√£o de frames e treinamento do modelo de vis√£o.
‚îú‚îÄ‚îÄ requeriments.txt            # Lista de todas as depend√™ncias Python.
‚îú‚îÄ‚îÄ Video visao computacional.mp4  # (Opcional) V√≠deo de entrada para o projeto de vis√£o.
‚îÇ
‚îú‚îÄ‚îÄ audio_formatado.mp3         # (Gerado) √Åudio extra√≠do pelo script de v√≠deo.
‚îú‚îÄ‚îÄ video_formatado.mp4         # (Gerado) V√≠deo sem √°udio.
‚îú‚îÄ‚îÄ base_frames.db              # (Gerado) Banco de dados SQLite com informa√ß√µes dos frames.
‚îú‚îÄ‚îÄ frames_video/               # (Gerado) Pasta com os frames extra√≠dos em formato JPG.
‚îú‚îÄ‚îÄ frames_video_fits/          # (Gerado) Pasta com os frames extra√≠dos em formato FITS.
‚îî‚îÄ‚îÄ *.keras                     # (Gerado) Modelos treinados salvos pelo Keras.
```

---

## üîß Pr√©-requisitos

Antes de come√ßar, garanta que voc√™ tenha os seguintes softwares instalados:
-   [Python 3.10+](https://www.python.org/downloads/)
-   [Pip](https://pip.pypa.io/en/stable/installation/) (geralmente vem com o Python)
-   [Git](https://git-scm.com/downloads/)

## ‚öôÔ∏è Passo a Passo da Instala√ß√£o

Siga estes passos para configurar seu ambiente de desenvolvimento.

### 1. Clonar o Reposit√≥rio

Abra seu terminal ou prompt de comando e clone este reposit√≥rio:
```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd <NOME_DO_REPOSITORIO>
```

### 2. Criar e Ativar um Ambiente Virtual

√â altamente recomend√°vel usar um ambiente virtual para isolar as depend√™ncias do projeto e evitar conflitos.

```bash
# Criar o ambiente virtual (pode usar 'venv' ou o nome que preferir)
python -m venv venv

# Ativar o ambiente virtual
# No Windows:
venv\Scripts\activate
# No macOS/Linux:
source venv/bin/activate
```
Voc√™ saber√° que o ambiente est√° ativo quando vir `(venv)` no in√≠cio do seu prompt de comando.

### 3. Instalar as Depend√™ncias

Com o ambiente virtual ativado, instale todas as bibliotecas necess√°rias usando o arquivo `requeriments.txt`.

```bash
pip install -r requeriments.txt
```
Este comando instalar√° todas as bibliotecas, incluindo `tensorflow`, `pandas`, `openai-whisper`, `nltk`, `moviepy`, entre outras.

### 4. Baixar Pacotes NLTK

O projeto de an√°lise de √°udio utiliza a biblioteca NLTK. Ap√≥s a instala√ß√£o, √© necess√°rio baixar alguns pacotes de dados espec√≠ficos para o processamento de texto em portugu√™s.

O notebook `Analisando_√°udio.ipynb` j√° cont√©m o c√≥digo para fazer isso. Ao executar a primeira c√©lula de c√≥digo, ele tentar√° baixar os seguintes pacotes:
-   `punkt` (para tokeniza√ß√£o)
-   `stopwords` (para lista de palavras de parada)
-   `wordnet` (para lematiza√ß√£o)

Caso encontre algum problema, voc√™ pode executar o download manualmente em um script Python:
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

---

## ‚ñ∂Ô∏è Como Executar os Modelos

Os dois projetos est√£o em notebooks Jupyter (`.ipynb`). Voc√™ pode abri-los usando o Jupyter Lab, Jupyter Notebook ou uma IDE como o VS Code com a extens√£o Jupyter.

### Parte 1: An√°lise e Classifica√ß√£o de V√≠deo (`Analisando_V√≠deo.ipynb`)

Este √© o primeiro notebook a ser executado, pois ele **gera o arquivo de √°udio** necess√°rio para a segunda parte.

#### **Passo 1: Preparar o V√≠deo de Entrada**
-   O notebook est√° configurado para baixar um v√≠deo de exemplo do Google Drive usando o comando `gdown`.
-   Alternativamente, voc√™ pode colocar seu pr√≥prio arquivo de v√≠deo no formato `.mp4` na pasta raiz do projeto. Se usar seu pr√≥prio v√≠deo, certifique-se de que o nome do arquivo seja **`Video visao computacional.mp4`** ou altere o nome no c√≥digo.

#### **Passo 2: Executar as C√©lulas do Notebook**
Abra o notebook `Analisando_V√≠deo.ipynb` e execute as c√©lulas em ordem.

1.  **Imports e Download**: A primeira c√©lula instala `moviepy` e baixa o v√≠deo de exemplo.
2.  **Separando √°udio e v√≠deo**: Esta c√©lula √© crucial. Ela ir√° criar dois novos arquivos na pasta raiz:
    -   `audio_formatado.mp3` (ser√° usado no outro notebook)
    -   `video_formatado.mp4` (v√≠deo sem √°udio, para processamento)
3.  **Criando base de dados e Extraindo frames**: Esta se√ß√£o criar√° as pastas `frames_video/`, `frames_video_fits/` e o arquivo `base_frames.db`. Este processo pode levar alguns minutos, dependendo da dura√ß√£o e resolu√ß√£o do v√≠deo.
4.  **Analisando imagem**: Demonstra como carregar uma imagem do banco de dados e aplicar a equaliza√ß√£o de histograma.
5.  **Rotulando os dados**: O c√≥digo rotula os frames no banco de dados com base em intervalos pr√©-definidos (`book`, `knife`, `cell phone`).
6.  **Preparando dados para o modelo**: Esta se√ß√£o carrega os dados para um DataFrame Pandas, aplica filtros e realiza o balanceamento e o aumento de dados (*Data Augmentation*).
7.  **Treinando o modelo**: A c√©lula `model.fit` iniciar√° o treinamento da Rede Neural.
    -   ‚ö†Ô∏è **Aten√ß√£o**: O treinamento de uma CNN √© um processo computacionalmente intensivo. Recomenda-se uma m√°quina com uma **GPU dedicada** (NVIDIA com CUDA) para acelerar o processo. Sem uma GPU, o treinamento pode levar v√°rias horas.
    -   Durante o treinamento, modelos de checkpoint (`.keras`) ser√£o salvos no diret√≥rio.
8.  **Analisando o resultado**: As c√©lulas finais ir√£o carregar o melhor modelo salvo e gerar gr√°ficos e m√©tricas de avalia√ß√£o, como a matriz de confus√£o e a curva ROC.

### Parte 2: An√°lise de √Åudio (`Analisando_√°udio.ipynb`)

Este notebook deve ser executado ap√≥s a **Parte 1**, pois depende do arquivo de √°udio gerado.

#### **Passo 1: Verificar o Arquivo de √Åudio**
-   Certifique-se de que o arquivo `audio_formatado.mp3` existe na pasta raiz do projeto. Ele deve ter sido criado ao executar a c√©lula "Separando √°udio e v√≠deo" do notebook `Analisando_V√≠deo.ipynb`.

#### **Passo 2: Executar as C√©lulas do Notebook**
Abra o notebook `Analisando_√°udio.ipynb` e execute as c√©lulas em ordem.

1.  **Imports**: Carrega todas as bibliotecas e baixa os pacotes NLTK, se necess√°rio.
2.  **Carregando modelo**: Carrega o modelo "base" do Whisper. O primeiro download pode demorar um pouco.
3.  **Transcrevendo √°udio**: L√™ o arquivo `audio_formatado.mp3` e exibe o texto transcrito.
4.  **Tratando o texto**: Realiza o pr√©-processamento do texto (tokeniza√ß√£o e lematiza√ß√£o).
5.  **Contagem de Palavras**: Conta a frequ√™ncia de cada palavra e exibe as 10 mais comuns.
6.  **Plot principais palavras**: Gera um gr√°fico de barras visualizando as palavras mais frequentes.

## üìä Entendendo os Resultados

Ap√≥s a execu√ß√£o completa de ambos os notebooks, voc√™ ter√° os seguintes artefatos:

-   **Texto Transcrito**: A sa√≠da da transcri√ß√£o do √°udio no notebook de √°udio.
-   **Gr√°fico de Frequ√™ncia**: Uma visualiza√ß√£o das palavras mais comuns no √°udio.
-   **Banco de Dados de Frames (`base_frames.db`)**: Um arquivo SQLite contendo metadados e os dados brutos de cada frame extra√≠do.
-   **Modelo Treinado (`.keras`)**: O arquivo contendo a arquitetura e os pesos da CNN treinada, pronto para ser usado para novas predi√ß√µes.
-   **M√©tricas de Avalia√ß√£o**: Gr√°ficos e relat√≥rios detalhados no notebook de v√≠deo que mostram o qu√£o bem o modelo de classifica√ß√£o de imagens performou.
